{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extraction - Code.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPXvpSxn61eLeuAXE7KU7Ik",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meaveryway/Backend_AntTech/blob/master/Extraction_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--kp_m24bAeC",
        "outputId": "b0cac610-49b6-4db7-ce98-0c75f431132f"
      },
      "source": [
        "!pip install pdfplumber\n",
        "import pdfplumber\n",
        "!pip install tika\n",
        "import tika\n",
        "tika.initVM()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.7/dist-packages (0.5.28)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfplumber) (7.1.2)\n",
            "Requirement already satisfied: Wand in /usr/local/lib/python3.7/dist-packages (from pdfplumber) (0.6.6)\n",
            "Requirement already satisfied: pdfminer.six==20200517 in /usr/local/lib/python3.7/dist-packages (from pdfplumber) (20200517)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20200517->pdfplumber) (2.4.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20200517->pdfplumber) (3.10.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20200517->pdfplumber) (3.0.4)\n",
            "Collecting tika\n",
            "  Downloading tika-1.24.tar.gz (28 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (57.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2021.5.30)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-py3-none-any.whl size=32893 sha256=43490c393f6f9e9cdc82bff85aea01e06a8bc5dda0ebc197c337e20bb760f8ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/2b/38/58ff05467a742e32f67f5d0de048fa046e764e2fbb25ac93f3\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-1.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhTrwe_IabFW"
      },
      "source": [
        "####Schema\n",
        "Then differentiate text fields for arabic and french"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuoXf6x_aZt8"
      },
      "source": [
        "code = {\n",
        "    'id':\n",
        "    'category':\n",
        "    'book_num':\n",
        "    'book':\n",
        "    'title_num':\n",
        "    'title':\n",
        "    'chapter_num'\n",
        "    'chapter':\n",
        "    'article_num':\n",
        "    'content':\n",
        "    'status':\n",
        "\n",
        "    'extraction_date':\n",
        "    \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMfs_wVrbTar"
      },
      "source": [
        "####File parsing\n",
        "1. Split pdf by page\n",
        "2. Convert to word (for Ar)\n",
        "3. Extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRUd8dBwZeUV"
      },
      "source": [
        "CODE_CIVIL_AR_PATH = \"/content/ACivil.pdf\"\n",
        "CODE_CIVIL_AR_PAGE_RANGE = [8, 171]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33AhbMwLbW0x"
      },
      "source": [
        "import pdfplumber\n",
        "def digitize_file_pdfplumber(file_path):\n",
        "  text = \"\"\n",
        "  with pdfplumber.open(file_path) as pdf:\n",
        "    page = pdf.pages[0].dedupe_chars(tolerance=1)\n",
        "    text = text + page.extract_text()\n",
        "  pdf.close()\n",
        "  return(text)\n",
        "  \n",
        "def roman_to_int(s):\n",
        "  rom_val = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}\n",
        "  int_val = 0\n",
        "  for i in range(len(s)):\n",
        "    if i > 0 and rom_val[s[i]] > rom_val[s[i - 1]]:\n",
        "      int_val += rom_val[s[i]] - 2 * rom_val[s[i - 1]]\n",
        "    else:\n",
        "      int_val += rom_val[s[i]]\n",
        "  return int_val"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU98gL96cga1",
        "outputId": "c69b35f6-6f4e-4025-8895-2e7b67ced4a0"
      },
      "source": [
        "extract = digitize_file_pdfplumber(\"/content/samp/document-page19.pdf\")\n",
        "import re\n",
        "_RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] xref found: pos=b'81503'\n",
            "[INFO] read_xref_from: start=81503, token=/b'xref'\n",
            "[INFO] xref objects: {1: (None, 9, 0), 2: (None, 68, 0), 3: (None, 108, 0), 4: (None, 263, 0), 5: (None, 312, 0), 6: (None, 1177, 0), 7: (None, 1226, 0), 8: (None, 1796, 0), 9: (None, 1905, 0), 10: (None, 2032, 0), 11: (None, 2182, 0), 12: (None, 2866, 0), 13: (None, 3066, 0), 14: (None, 41358, 0), 15: (None, 41820, 0), 16: (None, 41975, 0), 17: (None, 42645, 0), 18: (None, 42852, 0), 19: (None, 75675, 0), 20: (None, 76150, 0)}\n",
            "[INFO] trailer: {'Size': 21, 'Root': <PDFObjRef:4>, 'Info': <PDFObjRef:2>}\n",
            "[INFO] trailer: {'Size': 21, 'Root': <PDFObjRef:4>, 'Info': <PDFObjRef:2>}\n",
            "[INFO] Pages: Kids=[<PDFObjRef:3>]\n",
            "[INFO] Page: {'CropBox': [0, 0, 595, 842], 'Rotate': 0, 'Parent': <PDFObjRef:1>, 'Thumb': <PDFObjRef:5>, 'Resources': <PDFObjRef:8>, 'MediaBox': [0, 0, 595, 842], 'Type': /'Page', 'Contents': <PDFObjRef:20>}\n",
            "[INFO] Processing page: <PDFPage: Resources={'ExtGState': {'GS1': <PDFObjRef:9>}, 'Font': {'TT3': <PDFObjRef:10>, 'TT1': <PDFObjRef:15>}, 'ProcSet': [/'PDF', /'Text']}, MediaBox=[0, 0, 595, 842]>\n",
            "[INFO] render_contents: resources={'ExtGState': {'GS1': <PDFObjRef:9>}, 'Font': {'TT3': <PDFObjRef:10>, 'TT1': <PDFObjRef:15>}, 'ProcSet': [/'PDF', /'Text']}, streams=[<PDFStream(20): raw=5280, {'Filter': /'FlateDecode', 'Length': 5279}>], ctm=(1, 0, 0, 1, 0, 0)\n",
            "[INFO] get_font: create: objid=10, spec={'BaseFont': /'MKBEGC+TimesNewRoman', 'DescendantFonts': [<PDFObjRef:11>], 'Subtype': /'Type0', 'ToUnicode': <PDFObjRef:14>, 'Type': /'Font', 'Encoding': /'Identity-H'}\n",
            "[INFO] get_font: create: objid=None, spec={'BaseFont': /'MKBEGC+TimesNewRoman', 'Subtype': /'CIDFontType2', 'CIDSystemInfo': {'Supplement': 0, 'Registry': b'Adobe', 'Ordering': b'Identity'}, 'DW': 1000, 'FontDescriptor': <PDFObjRef:12>, 'W': [3, [250], 5, [408], 10, [180, 333], 12, [333], 15, [250, 333, 250, 277, 500], 20, 28, 500, 29, 30, 277, 36, [722], 38, [666, 722, 610], 42, [722], 44, [333, 389, 722, 610, 889, 722], 50, [722, 556, 722, 666, 556, 610, 722], 57, [722, 943], 66, [500], 68, [443, 500, 443, 500, 443, 333, 500], 75, [500, 277], 77, [277, 500, 277, 777, 500], 82, 84, 500, 85, [333, 389, 277, 500], 89, [500, 722, 500], 92, [500, 443], 106, 107, 443, 111, 115, 443, 118, 119, 277, 123, [500], 127, 128, 500, 131, [399], 170, [500], 176, [722, 500], 182, [333]], 'Type': /'Font', 'Encoding': /'Identity-H', 'ToUnicode': <PDFStream(14): raw=390, {'Filter': /'FlateDecode', 'Length': 389}>}\n",
            "[INFO] get_font: create: objid=15, spec={'BaseFont': /'ENRSNE+TimesNewRoman,Bold', 'DescendantFonts': [<PDFObjRef:16>], 'Subtype': /'Type0', 'ToUnicode': <PDFObjRef:19>, 'Type': /'Font', 'Encoding': /'Identity-H'}\n",
            "[INFO] get_font: create: objid=None, spec={'BaseFont': /'ENRSNE+TimesNewRoman,Bold', 'Subtype': /'CIDFontType2', 'CIDSystemInfo': {'Supplement': 0, 'Registry': b'Adobe', 'Ordering': b'Identity'}, 'DW': 1000, 'FontDescriptor': <PDFObjRef:17>, 'W': [3, [250], 10, [277, 333], 12, [333], 15, [250, 333, 250, 277, 500], 20, 28, 500, 29, 30, 333, 36, [722, 666, 722], 39, [722, 666, 610, 777], 43, [777, 389, 500], 47, [666, 943, 722, 777, 610, 777, 722, 556, 666, 722], 57, [722], 59, 60, 722, 66, [500], 68, [500, 556, 443, 556, 443, 333, 500, 556, 277, 333], 79, [277, 833, 556, 500, 556], 84, [556, 443, 389, 333, 556, 500, 722, 500], 92, [500, 443], 106, 107, 500, 111, 114, 443, 118, [277], 123, [500], 127, 128, 556, 131, [399], 169, 170, 500, 176, [722, 500], 182, [333]], 'Type': /'Font', 'Encoding': /'Identity-H', 'ToUnicode': <PDFStream(19): raw=403, {'Filter': /'FlateDecode', 'Length': 402}>}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z6qd_KsZUJY",
        "outputId": "6636a257-d45b-4aa7-ea38-dd995e0dfa19"
      },
      "source": [
        "test = \"1 -  of shit. this is what i don't need\"\n",
        "if re.match(r'\\d\\ -.*\\.', test):\n",
        "  print('ok')"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi-zKEqXUTBo",
        "outputId": "edc7dbab-3aae-4345-8f9b-b2183ecde5dc"
      },
      "source": [
        "text = _RE_COMBINE_WHITESPACE.sub(\" \", extract).strip()\n",
        "while len(text) > 0 and 'Art' in text:\n",
        "  if 'LIVRE' in text[:20]:\n",
        "    print('*found book')\n",
        "    book = text.split('LIVRE')[-1].split('TITRE')[0].strip()\n",
        "\n",
        "    if len(book) > 150 or len(book) < 15:\n",
        "      raise Exception(f\"Failed to extract book element: /{book}/\")    \n",
        "    text = text[text.index(book) + len(book):].strip() #purging mother text\n",
        "\n",
        "    book_num = book.split(' ')[0].strip()\n",
        "    book_num = roman_to_int(book_num)\n",
        "    book_label = \" \".join(book.split(' ')[1:])\n",
        "    print(f\"/{book}/, /{book_num}/, /{book_label}/\")\n",
        "\n",
        "  elif 'TITRE' in text[:20]:\n",
        "\n",
        "    print('*found title')\n",
        "\n",
        "    title_chapter = text.split('TITRE')[-1].split('Chapitre')[0].strip() #trying to split with the presence of 'Chapter ...' after the title\n",
        "    title_article = text.split('TITRE')[-1].split('Art')[0].strip() #trying to split with the presence of 'Art.' or 'Article 1er.' after the title\n",
        "    title = min([title_chapter, title_article], key=len)\n",
        "    if len(title) > 150 or len(title) < 15:\n",
        "      raise Exception(f\"Failed to extract title element: /{title}/\")\n",
        "    text = text[text.index(title) + len(title):].strip() #purging mother text\n",
        "\n",
        "    title_num = title.split(' ')[0].strip()\n",
        "    title_num = roman_to_int(title_num)\n",
        "    title_label = \" \".join(book.split(' ')[1:])\n",
        "    print(f\"/{title}/, /{title_num}/, /{title_label}/\")\n",
        "\n",
        "  elif 'Chapitre' in text[:20]:\n",
        "    print('*found chapter')\n",
        "    chapter_section = text.split('Chapitre')[1].split('Section')[0].strip() #trying to split with the presence of 'Section ...' after the title\n",
        "    chapter_article = text.split('Chapitre')[1].split('Art')[0].strip() #trying to split with the presence of 'Art.' or 'Article 1er.' after the title\n",
        "    chapter = min([chapter_section, chapter_article], key=len)\n",
        "    \n",
        "    if len(chapter) > 150 or len(chapter) < 10:\n",
        "      raise Exception(f\"Failed to extract chapter element: /{chapter}/\")\n",
        "    text = text[text.index(chapter) + len(chapter):].strip() #purging mother text\n",
        "    \n",
        "    chapter_num = chapter.split(' ')[0].strip()\n",
        "    chapter_num = roman_to_int(chapter_num)\n",
        "    chapter_label = \" \".join(chapter.split(' ')[1:])\n",
        "    print(f\"/{chapter}/, /{chapter_num}/, /{chapter_label}/\")\n",
        "\n",
        "  elif 'Section' in text[:20]:\n",
        "    print('*found Section')\n",
        "    section_article = text.split('Section')[-1].split('Art')[0].strip() #trying to split with the presence of 'Art.' or 'Article 1er.' after the section title\n",
        "    section_subsection = re.split(r'\\d\\ -.*\\.', text.split('Section')[-1])[0].strip() #trying to split with the presence of a subsection '1 - something' after the section title\n",
        "    \n",
        "    section = min([section_article, section_subsection], key=len)\n",
        "    \n",
        "    if len(section) > 150 or len(section) < 10:\n",
        "      raise Exception(f\"Failed to extract section element: /{section}/\")\n",
        "    text = text[text.index(section) + len(section):].strip() #purging mother text\n",
        "    \n",
        "    section_num = section.split(' ')[0].strip()\n",
        "    section_num = roman_to_int(section_num)\n",
        "    section_label = \" \".join(section.split(' ')[1:])\n",
        "    print(f\"/{section}/, /{section_num}/, /{section_label}/\")\n",
        "\n",
        "  #subsection\n",
        "  elif re.match(r'\\d\\ -.*\\.', text[:20]):\n",
        "    print('*found Sub-section')\n",
        "    subsection = text.split('Art')[0].strip() #trying to split with the presence of 'Art.' or 'Article 1er.' after the sub-section title    \n",
        "    \n",
        "    if len(subsection) > 150 or len(subsection) < 5:\n",
        "      raise Exception(f\"Failed to extract sub-section element: /{subsection}/\")\n",
        "    text = text[text.index(subsection) + len(subsection):].strip() #purging mother text\n",
        "    \n",
        "    subsection_num = subsection.split('-')[0].strip()\n",
        "    subsection_num = re.sub(r\"\\D\", \"\", subsection_num)\n",
        "\n",
        "    subsection_label = subsection[subsection.index('-') + 1 : subsection.rfind('.')].strip()\n",
        "    print(f\"/{subsection}/, /{subsection_num}/, /{subsection_label}/\")\n",
        "\n",
        "  elif 'Art.' in text[:10]:\n",
        "    print('*found article')\n",
        "    article_article = text.split('Art.')[1]\n",
        "    article_chapter = text.split('Art.')[1].split('Chapitre')[0]\n",
        "    article_section = text.split('Art.')[1].split('Section')[0]\n",
        "    article_end = text.split('Art.')[1].split('_____')[0] #to capture last article in page\n",
        "    article = min([article_article, article_chapter, article_section, article_end], key=len)\n",
        "\n",
        "\n",
        "    if len(article) < 20:\n",
        "      raise Exception(f\"Failed to extract article element: /{article}/\")\n",
        "    text = text[text.index(article) + len(article):].strip() #purging mother text\n",
        "\n",
        "    identifier = article.split('-')[0]\n",
        "    article_identifier = identifier.split('.')[0]\n",
        "    article_num = re.sub(r\"\\D\", \"\", article_identifier)\n",
        "    article_subnum = article_identifier.replace(article_num, ' ').strip()\n",
        "    article_status = identifier[identifier.rfind('('): identifier.rfind(')')]\n",
        "    article_status = re.sub(\"[^A-Za-zé]\", \"\", article_status)\n",
        "\n",
        "    article_text = article[article.index('-') + 1 : article.rfind('.') + 1].strip() #rfind to deal with cases where there's no footer ___ on the page\n",
        "    note_num = article[article.rfind('.') + 1:].strip()\n",
        "    note_num = re.sub(r\"\\D\", \"\", note_num)\n",
        "    print(f\"#{article_num}, {article_subnum} ({article_status}) [note: {note_num}]: {article_text}\")\n",
        "#print(f\"----- {text}\")\n",
        "#print(len(articles))"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*found Section\n",
            "/II DES CONDITIONS DU CONTRAT/, /2/, /DES CONDITIONS DU CONTRAT/\n",
            "*found Sub-section\n",
            "/1 - Du consentement./, /1/, /Du consentement/\n",
            "*found article\n",
            "#59,  () [note: ]: Le contrat se forme dès que les parties ont échangé leurs volontés concordantes, sans préjudice des dispositions légales.\n",
            "*found article\n",
            "#60,  () [note: ]: On peut déclarer sa volonté verbalement, par écrit ou par les signes généralement en usage ou encore par une conduite telle qu'elle ne laisse aucun doute sur la véritable intention de son auteur. La déclaration de volonté peut être tacite lorsque la loi ou les parties n'exigent pas qu'elle soit expresse.\n",
            "*found article\n",
            "#61,  () [note: ]: Une déclaration de volonté produit son effet dès qu'elle parvient à la connaissance de son destinataire. Celui-ci sera réputé avoir pris connaissance de la déclaration dès sa réception, à moins de preuve contraire.\n",
            "*found article\n",
            "#62,  () [note: ]: Si l'auteur de la déclaration décède ou devient incapable avant que celle-ci ne produise son effet, la déclaration n'est pas moins efficace au moment où elle parvient à la connaissance de son destinataire, à moins que le contraire ne résulte de la déclaration de volonté ou de la nature des choses.\n",
            "*found article\n",
            "#63,  () [note: ]: Lorsqu'un délai est fixé pour l'acceptation, l'auteur de l'offre est lié par son offre jusqu’à l'expiration de ce délai. La fixation du délai peut résulter implicitement des circonstances ou de la nature de l'affaire.\n",
            "*found article\n",
            "#64,  () [note: ]: Si, en séance contractuelle, une offre est faite à une personne présente, sans fixation de délai pour l'acceptation, l'auteur de l'offre est délié si l'acceptation n'a pas lieu immédiatement. Il en est de même si l'offre est faite de personne à personne au moyen du téléphone ou de tout autre moyen similaire. Toutefois, le contrat est conclu, même si l'acceptation n'est pas immédiate, lorsque, dans l'intervalle entre l'offre et l'acceptation, rien n'indique que l'auteur de l'offre l'ait rétractée, pourvu que la déclaration de l'acceptation ait lieu avant que la séance contractuelle ne prenne fin.\n",
            "*found article\n",
            "#65,  () [note: ]: Lorsque les parties ont exprimé leur accord sur tous les points essentiels du contrat et ont réservé de s'entendre par la suite sur des points de détails, sans stipuler que faute d'un tel accord, le contrat serait sans effet, ce contrat est réputé conclu, les points de détail seront alors, en cas de litige, déterminés par le tribunal, conformément à la nature de l'affaire, aux prescriptions de la loi, à l'usage et à l'équité.\n",
            "*found article\n",
            "#66,  () [note: 12]: L'acceptation qui modifie l'offre ne vaut que comme une offre nouvelle.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UckvyKJFRi0Y",
        "outputId": "40c1d777-6fa8-48a3-a9a7-98fc0f017f9b"
      },
      "source": [
        "for article in text.split('Art.')[1:]:\n",
        "  try:\n",
        "    article_num = article.split('.', 1)[0].strip()\n",
        "    contains_number = re.sub(r\"\\D\", \"\", article_num)\n",
        "    if not contains_number.isnumeric():\n",
        "      raise Exception(\"Not an article\")\n",
        "    print(f\"-{article_num}-\")\n",
        "  except:\n",
        "    print(f\"Not an article: /{article}/\")"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-2-\n",
            "-3-\n",
            "-4-\n",
            "-5-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rChxCjNdRf4K"
      },
      "source": [
        "####Tika"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evf_cHVde6en"
      },
      "source": [
        "data = digitize_file_tika(\"/content/samp/document-page19.pdf\")"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "EOX3gsKJjr4w",
        "outputId": "a17e7250-d381-4fec-8820-4696e5425c62"
      },
      "source": [
        "data"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<html xmlns=\"http://www.w3.org/1999/xhtml\">\\n<head>\\n<meta name=\"pdf:PDFVersion\" content=\"1.3\" />\\n<meta name=\"X-Parsed-By\" content=\"org.apache.tika.parser.DefaultParser\" />\\n<meta name=\"X-Parsed-By\" content=\"org.apache.tika.parser.pdf.PDFParser\" />\\n<meta name=\"pdf:hasXFA\" content=\"false\" />\\n<meta name=\"access_permission:modify_annotations\" content=\"true\" />\\n<meta name=\"access_permission:can_print_degraded\" content=\"true\" />\\n<meta name=\"access_permission:extract_for_accessibility\" content=\"true\" />\\n<meta name=\"access_permission:assemble_document\" content=\"true\" />\\n<meta name=\"xmpTPg:NPages\" content=\"1\" />\\n<meta name=\"resourceName\" content=\"b\\'document-page19.pdf\\'\" />\\n<meta name=\"pdf:hasXMP\" content=\"false\" />\\n<meta name=\"dc:format\" content=\"application/pdf; version=1.3\" />\\n<meta name=\"access_permission:extract_content\" content=\"true\" />\\n<meta name=\"access_permission:can_print\" content=\"true\" />\\n<meta name=\"access_permission:fill_in_form\" content=\"true\" />\\n<meta name=\"pdf:encrypted\" content=\"false\" />\\n<meta name=\"producer\" content=\"PyPDF2\" />\\n<meta name=\"access_permission:can_modify\" content=\"true\" />\\n<meta name=\"pdf:docinfo:producer\" content=\"PyPDF2\" />\\n<meta name=\"pdf:hasMarkedContent\" content=\"false\" />\\n<meta name=\"Content-Type\" content=\"application/pdf\" />\\n<title></title>\\n</head>\\n<body><div class=\"page\"><p />\\n<p> 12\\n</p>\\n<p>Section II \\nDES CONDITIONS DU CONTRAT \\n</p>\\n<p> \\n1 - Du consentement. \\n</p>\\n<p> \\nArt. 59.  - Le contrat se forme dès que les parties ont échangé leurs volontés concordantes, sans \\n</p>\\n<p>préjudice des dispositions légales. \\n</p>\\n<p> \\nArt. 60.  - On peut déclarer sa volonté verbalement, par écrit ou par les signes généralement en usage \\n</p>\\n<p>ou encore par une conduite telle qu\\'elle ne laisse aucun doute sur la véritable intention de son auteur. \\nLa déclaration de volonté peut être tacite lorsque la loi ou les parties n\\'exigent pas qu\\'elle soit \\n</p>\\n<p>expresse. \\n</p>\\n<p> \\nArt. 61.  - Une déclaration de volonté produit son effet dès qu\\'elle parvient à la connaissance de son \\n</p>\\n<p>destinataire. Celui-ci sera réputé avoir pris connaissance de la déclaration dès sa réception, à moins de \\npreuve contraire. \\n</p>\\n<p> \\nArt. 62.  - Si l\\'auteur de la déclaration décède ou devient incapable avant que celle-ci ne produise son \\n</p>\\n<p>effet, la déclaration n\\'est pas moins efficace au moment où elle parvient à la connaissance de son \\ndestinataire, à moins que le contraire ne résulte de la déclaration de volonté ou de la nature des choses. \\n</p>\\n<p> \\nArt.  63.  - Lorsqu\\'un délai est fixé pour l\\'acceptation, l\\'auteur de l\\'offre est lié par son offre jusqu’à \\n</p>\\n<p>l\\'expiration de ce délai. \\nLa fixation du délai peut résulter implicitement des circonstances ou de la nature de l\\'affaire. \\n</p>\\n<p> \\nArt. 64.  - Si, en séance contractuelle, une offre est faite à une personne présente, sans fixation de \\n</p>\\n<p>délai pour l\\'acceptation, l\\'auteur de l\\'offre est délié si l\\'acceptation n\\'a pas lieu immédiatement. Il en est de \\nmême si l\\'offre est faite de personne à personne au moyen du téléphone ou de tout autre moyen similaire. \\n</p>\\n<p>Toutefois, le contrat est conclu, même si l\\'acceptation n\\'est pas immédiate, lorsque, dans l\\'intervalle \\nentre l\\'offre et l\\'acceptation, rien n\\'indique que l\\'auteur de l\\'offre l\\'ait rétractée, pourvu que la déclaration \\nde l\\'acceptation ait lieu avant que la séance contractuelle ne prenne fin. \\n</p>\\n<p> \\nArt.  65.  - Lorsque les parties ont exprimé leur accord sur tous les points essentiels du contrat et ont \\n</p>\\n<p>réservé de s\\'entendre par la suite sur des points de détails, sans stipuler que faute d\\'un tel accord, le \\ncontrat serait sans effet, ce contrat est réputé conclu, les points de détail seront alors, en cas de litige, \\ndéterminés par le tribunal, conformément à la nature de l\\'affaire, aux prescriptions de la loi, à l\\'usage et à \\nl\\'équité. \\n</p>\\n<p> \\nArt.  66.  - L\\'acceptation qui modifie l\\'offre ne vaut que comme une offre nouvelle. </p>\\n<p />\\n</div>\\n</body></html>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zxCgluqiE02"
      },
      "source": [
        "xhtml_data = BeautifulSoup(data)\n",
        "for page, content in enumerate(xhtml_data.find_all('div', attrs={'class': 'page'})):\n",
        "    print('Parsing page {} of pdf file...'.format(page+1))\n",
        "    print(content)\n",
        "    #_buffer.write(str(content))\n",
        "    #parsed_content = parser.from_buffer(_buffer.getvalue())\n",
        "    #_buffer.truncate()\n",
        "    #file_data.append({'id': 'page_'+str(page+1), 'content': parsed_content['content']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLJkOs9Oe5rx"
      },
      "source": [
        "from tika import parser\n",
        "from bs4 import BeautifulSoup\n",
        "from io import StringIO\n",
        "from tika import detector\n",
        "def digitize_file_tika(file_path):\n",
        "    file_extension = detector.from_file(file_path)\n",
        "    if False:#'pdf'in str(file_extension).lower():\n",
        "      file_data = []\n",
        "      buffer = StringIO()\n",
        "      data = parser.from_file(file_path, xmlContent=True)\n",
        "      xhtml_data = BeautifulSoup(data['content'], features=\"lxml\")\n",
        "      for page, content in enumerate(xhtml_data.find_all('div', attrs={'class': 'page'})):\n",
        "          #print('Parsing page {} of pdf file...'.format(page+1))\n",
        "          buffer.write(str(content))\n",
        "          parsed_content = parser.from_buffer(buffer.getvalue())\n",
        "          buffer.truncate()\n",
        "          file_data.append({'id': str(page+1), 'content': parsed_content['content'].replace('\\n\\n', '').replace('\\n', ' ')})\n",
        "      #Clean-up\n",
        "      for i in reversed(range(1,len(file_data))) :\n",
        "        content = file_data[i]['content']\n",
        "        substract = file_data[i-1]['content']\n",
        "        modified_content = content.replace(substract, \"\")\n",
        "        file_data[i]['content'] = modified_content\n",
        "      return file_data\n",
        "    \n",
        "    else:\n",
        "      text = data = parser.from_file(file_path, xmlContent=True)['content']\n",
        "      return(text)\n",
        "\n",
        "    "
      ],
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJIBo3WbfEUQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSlwGyHCvsgF"
      },
      "source": [
        "####Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G6mn1IavuPR",
        "outputId": "309785ac-74d9-44c4-f38b-31d7692c3e94"
      },
      "source": [
        "!pip install pypdf2"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 36.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 4.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pypdf2\n",
            "  Building wheel for pypdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypdf2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61100 sha256=6a328fed4ac07955ba1d7ef479ddcc615c80652b2d9a4895d43270d00d9ef560\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1a/24/648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\n",
            "Successfully built pypdf2\n",
            "Installing collected packages: pypdf2\n",
            "Successfully installed pypdf2-1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E-FM6b9vt2G"
      },
      "source": [
        "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
        "\n",
        "inputpdf = PdfFileReader(open(\"/content/FCivil.pdf\", \"rb\"))\n",
        "\n",
        "for i in range(inputpdf.numPages):\n",
        "    output = PdfFileWriter()\n",
        "    output.addPage(inputpdf.getPage(i))\n",
        "    with open(\"/content/samp/document-page%s.pdf\" % i, \"wb\") as outputStream:\n",
        "        output.write(outputStream)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBUtCIxPvJg_"
      },
      "source": [
        "####Convert to Docx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2-yTeXuvL5E"
      },
      "source": [
        "!pip install pdf2docx\n",
        "from pdf2docx import Converter\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imaacgfvvVeR",
        "outputId": "4677894d-6fa4-4f1b-f9c3-7c9bb3b6e777"
      },
      "source": [
        "cv = Converter('/content/document-page0.pdf')\n",
        "cv.convert('/content/ACivilsamp.docx', start=0, end=None)\n",
        "cv.close()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Start to convert /content/document-page0.pdf\n",
            "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
            "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
            "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
            "[INFO] (1/1) Page 1\n",
            "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
            "[INFO] (1/1) Page 1\n",
            "[INFO] Terminated in 0.79s.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCr_NN9IvLLH"
      },
      "source": [
        "# # # dir_path for input reading and output files & a for loop # # #\n",
        "\n",
        "path_input = '/pdftodocx/input/'\n",
        "path_output = '/pdftodocx/output/'\n",
        "\n",
        "for file in os.listdir(path_input):\n",
        "    cv = Converter(path_input+file)\n",
        "    cv.convert(path_output+file+'.docx', start=0, end=None)\n",
        "    cv.close()\n",
        "    print(file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}